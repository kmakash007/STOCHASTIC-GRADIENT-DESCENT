# STOCHASTIC-GRADIENT-DESCENT
Stochastic gradient descent (SGD), often abbreviated as SGD, is an optimization algorithm widely used in machine learning for training models. It's an iterative approach that helps us find the minimum value (or optimum) of a function. This minimum value is often referred to as the loss function in machine learning.
